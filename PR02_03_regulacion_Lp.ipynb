{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dr-Carlos-Villasenor/PatternRecognition/blob/main/PR02_03_regulacion_Lp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QhdjMwRzhrW"
      },
      "source": [
        "# Reconocimeinto de Patrones\n",
        "## Dr. Carlos Vilaseñor\n",
        "## Regulación Lp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkpmUjH9zhra"
      },
      "source": [
        "Los métodos de regularización son técnicas en ML que nos permiten mitigar el problema de sobreentrenamiento. Existen muchas técnicas con efecto regulatorio en está practica nos centraremos en regulación L1 y L2, en el caso de ser usadas en el modelo lineal reciben los nombres de Lasso y Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zPdGoxGzhrb"
      },
      "source": [
        "Primeramente importemos toda la paquetería que usaremos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GPZCKpzwzhrb"
      },
      "outputs": [],
      "source": [
        "# Páquetes básicos\n",
        "import numpy as np\n",
        "import numpy.random as rnd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Páquetes de sklearn\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mntnssjpzhrd"
      },
      "source": [
        "Al igual que la práctica anterior vamos a crear datos sintéticos para este experimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SZ5AQYkuzhre"
      },
      "outputs": [],
      "source": [
        "# Semilla del generador pseudoaleatorio\n",
        "np.random.seed(42)\n",
        "\n",
        "# Número de muestras\n",
        "m = 100\n",
        "x = 6 * np.random.rand(m, 1) - 3\n",
        "y = 0.5 * x**2 + x + 2 + np.random.randn(m, 1)\n",
        "\n",
        "# Particionar dataset\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25)\n",
        "\n",
        "# Creamos una serie de datos de -3 a 3 interpolados linealmente\n",
        "x_new=np.linspace(-3, 3, 200).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwKu_da1zhrf"
      },
      "source": [
        "# Ridge (Regulación L2 del modelo lineal)\n",
        "\n",
        "La regulación Ridge es un método para regulación lineal múltiple para escenarios donde las variables independietes están altamente correlacionadas.\n",
        "\n",
        "$$\\min_{\\beta} \\frac{1}{2n} \\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2 + \\frac{\\alpha}{2} \\sum_{i=1}^p \\beta_i^2$$\n",
        "\n",
        "donde $\\beta$ son los parámetros del modelo lineal y $\\alpha$ es una constante de regulación. Notese que cuando $\\alpha=0$ el método termina siendo el mismo que el de regresión lineal. Experimente con el siguiente código para ver las diferencias de predicción según el coheficiente $\\alpha$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4Q8D4eizhrf"
      },
      "outputs": [],
      "source": [
        "# Constante de regulación\n",
        "alpha = 0\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = Pipeline([ (\"poly_features\", PolynomialFeatures(degree=300, include_bias=False)),\n",
        "                    (\"std_scaler\", StandardScaler()),\n",
        "                    (\"lasso\", Ridge(alpha))])\n",
        "\n",
        "# Entrenamos el modelo\n",
        "model.fit(xtrain, ytrain)\n",
        "\n",
        "# Calculamos el desempeño del modelo (r2_score)\n",
        "print('Train: ', model.score(xtrain, ytrain))\n",
        "print('Test: ', model.score(xtest, ytest))\n",
        "\n",
        "\n",
        "# Dibujar salida\n",
        "y_new = model.predict(x_new)\n",
        "plt.plot(x_new, y_new, 'k-', label='modelo', linewidth=2)\n",
        "plt.plot(xtrain, ytrain, \"b.\", label='train', linewidth=3)\n",
        "plt.plot(xtest, ytest, \"r.\",label='test', linewidth=3)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$y$\")\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3Qd0VQazhrg"
      },
      "source": [
        "# LASSO (Regulación L1 del modelo lineal)\n",
        "\n",
        "La regulación Lasso viene del acrónimo en inglés de \"least absolute shrinkage and selection operator\" se usa como regulador y selector de variables. Se obtiene al reducir la siguiente función de costó sobre el modelo lineal.\n",
        "\n",
        "$$\\min_{\\beta} \\frac{1}{2n} \\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2 + \\alpha \\sum_{i}^p |\\beta_i|$$\n",
        "\n",
        "donde $\\beta$ son los parámetros del modelo lineal y $\\alpha$ es una constante de regulación. Experimente con el siguiente código para ver las diferencias de predicción según el coheficiente $\\alpha$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFcPk747zhri"
      },
      "outputs": [],
      "source": [
        "# Constante de regulación\n",
        "alpha = 0\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = Pipeline([ (\"poly_features\", PolynomialFeatures(degree=300, include_bias=False)),\n",
        "                    (\"std_scaler\", StandardScaler()),\n",
        "                    (\"lasso\", Lasso(alpha))])\n",
        "\n",
        "# Entrenamos el modelo\n",
        "model.fit(xtrain, ytrain)\n",
        "\n",
        "# Calculamos el desempeño del modelo (r2_score)\n",
        "print('Train: ', model.score(xtrain, ytrain))\n",
        "print('Test: ', model.score(xtest, ytest))\n",
        "\n",
        "\n",
        "# Dibujar salida\n",
        "y_new = model.predict(x_new)\n",
        "plt.plot(x_new, y_new, 'k-', label='modelo', linewidth=2)\n",
        "plt.plot(xtrain, ytrain, \"b.\", label='train', linewidth=3)\n",
        "plt.plot(xtest, ytest, \"r.\",label='test', linewidth=3)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$y$\")\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t62FyRzHzhrj"
      },
      "source": [
        "# ElasticNet (Regulación L1 y L2 del modelo lineal)\n",
        "\n",
        "El método ElasticNet es la combinación de los dos anteriores, por lo que la función de costo que se minimiza es la siguiente.\n",
        "\n",
        "$$\\min_{\\beta} \\frac{1}{2n} \\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2 + \\alpha \\left( \\frac{1 - \\lambda}{2} \\sum_{i=1}^p \\beta_i^2 + \\lambda \\sum_{i}^p |\\beta_i| \\right)$$\n",
        "\n",
        "donde $\\beta$ son los parámetros del modelo lineal y $\\alpha$ es una constante de regulación; $\\lambda$ es un numero entre 0 y 1 que media el uso de regulación L1 y L2, de manera de que si $\\lambda=0$, estariamos usando Ridge y si  $\\lambda=1$ estaríamos sando Lasso.\n",
        "\n",
        "Experimente con el siguiente código para ver las diferencias de predicción según el coheficiente $\\alpha$ y la razón $\\lambda$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08AkRwzBzhrj"
      },
      "outputs": [],
      "source": [
        "# Constante de regulación\n",
        "alpha = 0.0\n",
        "l1_ratio = 0.5\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = Pipeline([ (\"poly_features\", PolynomialFeatures(degree=300, include_bias=False)),\n",
        "                    (\"std_scaler\", StandardScaler()),\n",
        "                    (\"lasso\", ElasticNet(alpha=alpha, l1_ratio=l1_ratio))])\n",
        "\n",
        "# Entrenamos el modelo\n",
        "model.fit(xtrain, ytrain)\n",
        "\n",
        "# Calculamos el desempeño del modelo (r2_score)\n",
        "print('Train: ', model.score(xtrain, ytrain))\n",
        "print('Test: ', model.score(xtest, ytest))\n",
        "\n",
        "\n",
        "# Dibujar salida\n",
        "y_new = model.predict(x_new)\n",
        "plt.plot(x_new, y_new, 'k-', label='modelo', linewidth=2)\n",
        "plt.plot(xtrain, ytrain, \"b.\", label='train', linewidth=3)\n",
        "plt.plot(xtest, ytest, \"r.\",label='test', linewidth=3)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$y$\")\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}